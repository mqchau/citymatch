{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 1 \n",
      "\n",
      "Processing page 2 \n",
      "\n",
      "Processing page 3 \n",
      "\n",
      "Processing page 4 \n",
      "\n",
      "Processing page 5 \n",
      "\n",
      "Processing page 6 \n",
      "\n",
      "Processing page 7 \n",
      "\n",
      "Processing page 8 \n",
      "\n",
      "Processing page 9 \n",
      "\n",
      "Processing page 10 \n",
      "\n",
      "Processing page 11 \n",
      "\n",
      "Processing page 12 \n",
      "\n",
      "Processing page 13 \n",
      "\n",
      "Processing page 14 \n",
      "\n",
      "Processing page 15 \n",
      "\n",
      "Processing page 16 \n",
      "\n",
      "Processing page 17 \n",
      "\n",
      "Processing page 18 \n",
      "\n",
      "Processing page 19 \n",
      "\n",
      "Processing page 20 \n",
      "\n",
      "Processing page 21 \n",
      "\n",
      "Processing page 22 \n",
      "\n",
      "Processing page 23 \n",
      "\n",
      "Processing page 24 \n",
      "\n",
      "Processing page 25 \n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# remove extra \\n and sub-cities\n",
    "def filter_paren(s):\n",
    "    if '(' in s:\n",
    "        return False\n",
    "    if ')' in s:\n",
    "        return False\n",
    "    if '' == s:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def clean_data(cities):\n",
    "    c = cities.split('\\n\\n')\n",
    "    for ind, city_state in enumerate(c):\n",
    "        c[ind] = c[ind].strip() #takes out \\n in front and behind '\\ncity, state\\n'\n",
    "    \n",
    "    return list(filter(filter_paren, c))\n",
    "    \n",
    "\n",
    "def get_list_of_city():\n",
    "    out = []\n",
    "    url = \"http://www.topix.com/city/list/\"\n",
    "    for i in range(1,26):\n",
    "        print('Processing page %d \\n' %i)\n",
    "        handle = requests.get(url+'p'+str(i))\n",
    "        data = handle.text\n",
    "        soup = BeautifulSoup(data, 'html.parser')\n",
    "        d = soup.find_all('ul', class_='dir_col')\n",
    "        for i in range(len(d)-1):\n",
    "            out.extend(clean_data(d[i].get_text()))\n",
    "    return out\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    list_of_city = get_list_of_city()\n",
    "    f = open('cities.txt', 'w')\n",
    "    for s in list_of_city:\n",
    "        f.writelines(s+'\\n')\n",
    "    f.close()\n",
    "    print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
